{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "1. Reading in the Kaggle data and adding features\n",
    "2. Using a **`Pipeline`** for proper cross-validation\n",
    "3. Combining **`GridSearchCV`** with **`Pipeline`**\n",
    "4. Efficiently searching for tuning parameters using **`RandomizedSearchCV`**\n",
    "5. Adding features to a document-term matrix (using SciPy)\n",
    "6. Adding features to a document-term matrix (using **`FeatureUnion`**)\n",
    "7. Ensembling models\n",
    "8. Locating groups of similar cuisines\n",
    "9. Model stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for Python 2: use print only as a function\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Reading in the Kaggle data and adding features\n",
    "\n",
    "- Our goal is to predict the **cuisine** of a recipe, given its **ingredients**.\n",
    "- **Feature engineering** is the process through which you create features that don't natively exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that accepts a DataFrame and adds new features\n",
    "def make_features(df):\n",
    "    \n",
    "    # number of ingredients\n",
    "    df['num_ingredients'] = df.ingredients.apply(len)\n",
    "    \n",
    "    # mean length of ingredient names\n",
    "    df['ingredient_length'] = df.ingredients.apply(lambda x: np.mean([len(item) for item in x]))\n",
    "    \n",
    "    # string representation of the ingredient list\n",
    "    df['ingredients_str'] = df.ingredients.astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the same features in the training data and the new data\n",
    "train = make_features(pd.read_json('../data/train.json'))\n",
    "new = make_features(pd.read_json('../data/test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>[u'romaine lettuce', u'black olives', u'grape ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "      <td>[u'plain flour', u'ground pepper', u'salt', u'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>[u'eggs', u'pepper', u'salt', u'mayonaise', u'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>[u'water', u'vegetable oil', u'wheat', u'salt']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>[u'black pepper', u'shallots', u'cornflour', u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients  \\\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]   \n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "   num_ingredients  ingredient_length  \\\n",
       "0                9          12.000000   \n",
       "1               11          10.090909   \n",
       "2               12          10.333333   \n",
       "3                4           6.750000   \n",
       "4               20          10.100000   \n",
       "\n",
       "                                     ingredients_str  \n",
       "0  [u'romaine lettuce', u'black olives', u'grape ...  \n",
       "1  [u'plain flour', u'ground pepper', u'salt', u'...  \n",
       "2  [u'eggs', u'pepper', u'salt', u'mayonaise', u'...  \n",
       "3    [u'water', u'vegetable oil', u'wheat', u'salt']  \n",
       "4  [u'black pepper', u'shallots', u'cornflour', u...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>[baking powder, eggs, all-purpose flour, raisi...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>[u'baking powder', u'eggs', u'all-purpose flou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>[sugar, egg yolks, corn starch, cream of tarta...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.272727</td>\n",
       "      <td>[u'sugar', u'egg yolks', u'corn starch', u'cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>[sausage links, fennel bulb, fronds, olive oil...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>[u'sausage links', u'fennel bulb', u'fronds', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>[meat cuts, file powder, smoked sausage, okra,...</td>\n",
       "      <td>21</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>[u'meat cuts', u'file powder', u'smoked sausag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>[ground black pepper, salt, sausage casings, l...</td>\n",
       "      <td>8</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>[u'ground black pepper', u'salt', u'sausage ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        ingredients  num_ingredients  \\\n",
       "0  18009  [baking powder, eggs, all-purpose flour, raisi...                6   \n",
       "1  28583  [sugar, egg yolks, corn starch, cream of tarta...               11   \n",
       "2  41580  [sausage links, fennel bulb, fronds, olive oil...                6   \n",
       "3  29752  [meat cuts, file powder, smoked sausage, okra,...               21   \n",
       "4  35687  [ground black pepper, salt, sausage casings, l...                8   \n",
       "\n",
       "   ingredient_length                                    ingredients_str  \n",
       "0           9.333333  [u'baking powder', u'eggs', u'all-purpose flou...  \n",
       "1          10.272727  [u'sugar', u'egg yolks', u'corn starch', u'cre...  \n",
       "2           9.666667  [u'sausage links', u'fennel bulb', u'fronds', ...  \n",
       "3          12.000000  [u'meat cuts', u'file powder', u'smoked sausag...  \n",
       "4          13.000000  [u'ground black pepper', u'salt', u'sausage ca...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Using a `Pipeline` for proper cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = train.ingredients_str\n",
    "y = train.cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [u'romaine lettuce', u'black olives', u'grape ...\n",
       "1    [u'plain flour', u'ground pepper', u'salt', u'...\n",
       "2    [u'eggs', u'pepper', u'salt', u'mayonaise', u'...\n",
       "3      [u'water', u'vegetable oil', u'wheat', u'salt']\n",
       "4    [u'black pepper', u'shallots', u'cornflour', u...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X is just a Series of strings\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace the regex pattern that is used for tokenization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(token_pattern=r\"'([a-z ]+)'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate Multinomial Naive Bayes (with the default parameters)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[make_pipeline documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a pipeline of vectorization and Naive Bayes\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(vect, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countvectorizer',\n",
       "  CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "          dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "          vocabulary=None)),\n",
       " ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the pipeline steps\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proper cross-validation:**\n",
    "\n",
    "- By passing our pipeline to **`cross_val_score`**, features will be created from **`X`** (via **`CountVectorizer`**) within each fold of cross-validation.\n",
    "- This process simulates the real world, in which your out-of-sample data will contain **features that were not seen** during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73228849337901514"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validate the entire pipeline\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(pipe, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Combining `GridSearchCV` with `Pipeline`\n",
    "\n",
    "- We use **`GridSearchCV`** to locate optimal tuning parameters by performing an \"exhaustive grid search\" of different parameter combinations, searching for the combination that has the best cross-validated accuracy.\n",
    "- By passing a **`Pipeline`** to **`GridSearchCV`** (instead of just a model), we can search tuning parameters for both the vectorizer and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multinomialnb', 'countvectorizer']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline steps are automatically assigned names by make_pipeline\n",
    "pipe.named_steps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"],\n",
       " 'multinomialnb__alpha': [0.5, 1]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a grid of parameters to search (and specify the pipeline step along with the parameter)\n",
    "param_grid = {}\n",
    "param_grid['countvectorizer__token_pattern'] = [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]\n",
    "param_grid['multinomialnb__alpha'] = [0.5, 1]\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GridSearchCV documentation](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pass the pipeline (instead of the model) to GridSearchCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "        vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"], 'multinomialnb__alpha': [0.5, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time the grid search\n",
    "%time grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.72439, std: 0.00472, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.5},\n",
       " mean: 0.72326, std: 0.00484, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 1},\n",
       " mean: 0.74770, std: 0.00460, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.5},\n",
       " mean: 0.73229, std: 0.00552, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 1}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the score for each combination of parameters\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.747699502187\n",
      "{'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# print the single best score and parameters that produced that score\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Efficiently searching for tuning parameters using `RandomizedSearchCV`\n",
    "\n",
    "- When there are many parameters to tune, searching all possible combinations of parameter values may be **computationally infeasible**.\n",
    "- **`RandomizedSearchCV`** searches a sample of the parameter values, and you control the computational \"budget\".\n",
    "\n",
    "[RandomizedSearchCV documentation](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.RandomizedSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scipy.stats documentation](http://docs.scipy.org/doc/scipy/reference/stats.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__min_df': [1, 2, 3],\n",
       " 'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"],\n",
       " 'multinomialnb__alpha': <scipy.stats._distn_infrastructure.rv_frozen at 0xe2af8d0>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for any continuous parameters, specify a distribution instead of a list of options\n",
    "import scipy as sp\n",
    "param_grid = {}\n",
    "param_grid['countvectorizer__token_pattern'] = [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]\n",
    "param_grid['countvectorizer__min_df'] = [1, 2, 3]\n",
    "param_grid['multinomialnb__alpha'] = sp.stats.uniform(scale=1)\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set a random seed for sp.stats.uniform\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# additional parameters are n_iter (number of searches) and random_state\n",
    "rand = RandomizedSearchCV(pipe, param_grid, cv=5, scoring='accuracy', n_iter=5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 44.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "        vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "          fit_params={}, iid=True, n_iter=5, n_jobs=1,\n",
       "          param_distributions={'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"], 'multinomialnb__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000000000E2AF8D0>, 'countvectorizer__min_df': [1, 2, 3]},\n",
       "          pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
       "          scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time the randomized search\n",
    "%time rand.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.74986, std: 0.00494, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.417022004702574, 'countvectorizer__min_df': 2},\n",
       " mean: 0.72462, std: 0.00446, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.7203244934421581, 'countvectorizer__min_df': 1},\n",
       " mean: 0.72829, std: 0.00537, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.00011437481734488664, 'countvectorizer__min_df': 2},\n",
       " mean: 0.75137, std: 0.00438, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.30233257263183977, 'countvectorizer__min_df': 2},\n",
       " mean: 0.72233, std: 0.00450, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.14675589081711304, 'countvectorizer__min_df': 1}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751370241867\n",
      "{'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.30233257263183977, 'countvectorizer__min_df': 2}\n"
     ]
    }
   ],
   "source": [
    "print(rand.best_score_)\n",
    "print(rand.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X_new as the ingredient text\n",
    "X_new = new.ingredients_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "        vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=0.302332572632, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the best model found by RandomizedSearchCV\n",
    "rand.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'british', u'southern_us', u'italian', ..., u'italian',\n",
       "       u'southern_us', u'mexican'], \n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomizedSearchCV/GridSearchCV automatically refit the best model with the entire dataset, and can be used to make predictions\n",
    "new_pred_class_rand = rand.predict(X_new)\n",
    "new_pred_class_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a submission file (score: 0.75342)\n",
    "pd.DataFrame({'id':new.id, 'cuisine':new_pred_class_rand}).set_index('id').to_csv('sub3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Adding features to a document-term matrix (using SciPy)\n",
    "\n",
    "- So far, we've trained models on either the **document-term matrix** or the **manually created features**, but not both.\n",
    "- To train a model on both types of features, we need to **combine them into a single feature matrix**.\n",
    "- Because one of the matrices is **sparse** and the other is **dense**, the easiest way to combine them is by using SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6250)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a document-term matrix from all of the training data\n",
    "X_dtm = vect.fit_transform(X)\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scipy.sparse documentation](http://docs.scipy.org/doc/scipy/reference/sparse.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of the manually created features\n",
    "X_manual = train.loc[:, ['num_ingredients', 'ingredient_length']]\n",
    "X_manual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a sparse matrix from the DataFrame\n",
    "X_manual_sparse = sp.sparse.csr_matrix(X_manual)\n",
    "type(X_manual_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6252)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the two sparse matrices\n",
    "X_dtm_manual = sp.sparse.hstack([X_dtm, X_manual_sparse])\n",
    "X_dtm_manual.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This was a relatively easy process.\n",
    "- However, it does not allow us to do **proper cross-validation**, and it doesn't integrate well with the rest of the **scikit-learn workflow**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Adding features to a document-term matrix (using `FeatureUnion`)\n",
    "\n",
    "- Below is an alternative process that does allow for proper cross-validation, and does integrate well with the scikit-learn workflow.\n",
    "- To use this process, we have to learn about transformers, **`FunctionTransformer`**, and **`FeatureUnion`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are \"transformers\"?\n",
    "\n",
    "Transformer objects provide a `transform` method in order to perform **data transformations**. Here are a few examples:\n",
    "\n",
    "- **`CountVectorizer`**\n",
    "    - `fit` learns the vocabulary\n",
    "    - `transform` creates a document-term matrix using the vocabulary\n",
    "- **`Imputer`**\n",
    "    - `fit` learns the value to impute\n",
    "    - `transform` fills in missing entries using the imputation value\n",
    "- **`StandardScaler`**\n",
    "    - `fit` learns the mean and scale of each feature\n",
    "    - `transform` standardizes the features using the mean and scale\n",
    "- **`HashingVectorizer`**\n",
    "    - `fit` is not used, and thus it is known as a \"stateless\" transformer\n",
    "    - `transform` creates the document-term matrix using a hash of the token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting a function into a transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that accepts a DataFrame returns the manually created features\n",
    "def get_manual(df):\n",
    "    return df.loc[:, ['num_ingredients', 'ingredient_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_ingredients  ingredient_length\n",
       "0                9          12.000000\n",
       "1               11          10.090909\n",
       "2               12          10.333333\n",
       "3                4           6.750000\n",
       "4               20          10.100000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_manual(train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[FunctionTransformer documentation](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html) (new in 0.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.preprocessing._function_transformer.FunctionTransformer"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a stateless transformer from the get_manual function\n",
    "get_manual_ft = FunctionTransformer(get_manual, validate=False)\n",
    "type(get_manual_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_ingredients  ingredient_length\n",
       "0                9          12.000000\n",
       "1               11          10.090909\n",
       "2               12          10.333333\n",
       "3                4           6.750000\n",
       "4               20          10.100000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute the function using the transform method\n",
    "get_manual_ft.transform(train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that accepts a DataFrame returns the ingredients string\n",
    "def get_text(df):\n",
    "    return df.ingredients_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [u'romaine lettuce', u'black olives', u'grape ...\n",
       "1    [u'plain flour', u'ground pepper', u'salt', u'...\n",
       "2    [u'eggs', u'pepper', u'salt', u'mayonaise', u'...\n",
       "3      [u'water', u'vegetable oil', u'wheat', u'salt']\n",
       "4    [u'black pepper', u'shallots', u'cornflour', u...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and test another transformer\n",
    "get_text_ft = FunctionTransformer(get_text, validate=False)\n",
    "get_text_ft.transform(train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining feature extraction steps\n",
    "\n",
    "- **`FeatureUnion`** applies a list of transformers in parallel to the input data (not sequentially), then **concatenates the results**.\n",
    "- This is useful for combining several feature extraction mechanisms into a single transformer.\n",
    "\n",
    "![Pipeline versus FeatureUnion](06_pipeline_versus_featureunion.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[make_union documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_union.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6250)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a document-term matrix from all of the training data\n",
    "X_dtm = vect.fit_transform(X)\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6250)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is identical to a FeatureUnion with just one transformer\n",
    "union = make_union(vect)\n",
    "X_dtm = union.fit_transform(X)\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try to add a second transformer to the Feature Union (what's wrong with this?)\n",
    "# union = make_union(vect, get_manual_ft)\n",
    "# X_dtm_manual = union.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6252)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# properly combine the transformers into a FeatureUnion\n",
    "union = make_union(make_pipeline(get_text_ft, vect), get_manual_ft)\n",
    "X_dtm_manual = union.fit_transform(train)\n",
    "X_dtm_manual.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pipeline in a FeatureUnion](06_pipeline_in_a_featureunion.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71028951068529533"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slightly improper cross-validation\n",
    "cross_val_score(nb, X_dtm_manual, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a pipeline of the FeatureUnion and Naive Bayes\n",
    "pipe = make_pipeline(union, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71343183886118777"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# properly cross-validate the entire pipeline (and pass it the entire DataFrame)\n",
    "cross_val_score(pipe, train, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way to specify `Pipeline` and `FeatureUnion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reminder of how we created the pipeline\n",
    "union = make_union(make_pipeline(get_text_ft, vect), get_manual_ft)\n",
    "pipe = make_pipeline(union, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pipeline documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and [FeatureUnion documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# duplicate the pipeline structure without using make_pipeline or make_union\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "pipe = Pipeline([\n",
    "    ('featureunion', FeatureUnion([\n",
    "            ('pipeline', Pipeline([\n",
    "                    ('functiontransformer', get_text_ft),\n",
    "                    ('countvectorizer', vect)\n",
    "                    ])),\n",
    "            ('functiontransformer', get_manual_ft)\n",
    "        ])),\n",
    "    ('multinomialnb', nb)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search of a nested `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('featureunion', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('pipeline', Pipeline(steps=[('functiontransformer', FunctionTransformer(accept_sparse=False,\n",
       "            func=<function get_text at 0x000000000E2B05F8>, pass_y=False,\n",
       "            validate=False)), ('countvectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'stric...         func=<function get_manual at 0x000000000E2B5588>, pass_y=False,\n",
       "            validate=False))],\n",
       "         transformer_weights=None)),\n",
       " ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the pipeline steps\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'featureunion__pipeline__countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b',\n",
       "  \"'([a-z ]+)'\"],\n",
       " 'multinomialnb__alpha': [0.5, 1]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a grid of parameters to search (and specify the pipeline step along with the parameter)\n",
    "param_grid = {}\n",
    "param_grid['featureunion__pipeline__countvectorizer__token_pattern'] = [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]\n",
    "param_grid['multinomialnb__alpha'] = [0.5, 1]\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline', Pipeline(steps=[('functiontransformer', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function get_text at 0x000000000E2B05F8>, pass_y=False,\n",
       "          validate=False)), ('countvectorizer', CountVectorize...ormer_weights=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'featureunion__pipeline__countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"], 'multinomialnb__alpha': [0.5, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time grid.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.742671091668\n",
      "{'featureunion__pipeline__countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Ensembling models\n",
    "\n",
    "Rather than combining features into a single feature matrix and training a single model, we can instead create separate models and \"ensemble\" them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is ensembling?\n",
    "\n",
    "Ensemble learning (or \"ensembling\") is the process of combining several predictive models in order to produce a combined model that is **better than any individual model**.\n",
    "\n",
    "- **Regression:** average the predictions made by the individual models\n",
    "- **Classification:** let the models \"vote\" and use the most common prediction, or average the predicted probabilities\n",
    "\n",
    "For ensembling to work well, the models must have the following characteristics:\n",
    "\n",
    "- **Accurate:** they outperform the null model\n",
    "- **Independent:** their predictions are generated using different \"processes\", such as:\n",
    "    - different types of models\n",
    "    - different features\n",
    "    - different tuning parameters\n",
    "\n",
    "**The big idea:** If you have a collection of individually imperfect (and independent) models, the \"one-off\" mistakes made by each model are probably not going to be made by the rest of the models, and thus the mistakes will be discarded when averaging the models.\n",
    "\n",
    "**Note:** There are also models that have built-in ensembling, such as Random Forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: KNN model using only manually created features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "feature_cols = ['num_ingredients', 'ingredient_length']\n",
    "X = train[feature_cols]\n",
    "y = train.cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use KNN with K=800\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=800, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train KNN on all of the training data\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X_new as the manually created features\n",
    "X_new = new[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944L, 20L)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities of class membership for the new data\n",
    "new_pred_prob_knn = knn.predict_proba(X_new)\n",
    "new_pred_prob_knn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02625,  0.0275 ,  0.01375,  0.04375,  0.03375,  0.08   ,\n",
       "        0.0175 ,  0.075  ,  0.0275 ,  0.135  ,  0.01   ,  0.075  ,\n",
       "        0.01875,  0.165  ,  0.00875,  0.0125 ,  0.1525 ,  0.025  ,\n",
       "        0.0275 ,  0.025  ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print predicted probabilities for the first row only\n",
    "new_pred_prob_knn[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'brazilian', 0.026249999999999999),\n",
       " (u'british', 0.0275),\n",
       " (u'cajun_creole', 0.01375),\n",
       " (u'chinese', 0.043749999999999997),\n",
       " (u'filipino', 0.033750000000000002),\n",
       " (u'french', 0.080000000000000002),\n",
       " (u'greek', 0.017500000000000002),\n",
       " (u'indian', 0.074999999999999997),\n",
       " (u'irish', 0.0275),\n",
       " (u'italian', 0.13500000000000001),\n",
       " (u'jamaican', 0.01),\n",
       " (u'japanese', 0.074999999999999997),\n",
       " (u'korean', 0.018749999999999999),\n",
       " (u'mexican', 0.16500000000000001),\n",
       " (u'moroccan', 0.0087500000000000008),\n",
       " (u'russian', 0.012500000000000001),\n",
       " (u'southern_us', 0.1525),\n",
       " (u'spanish', 0.025000000000000001),\n",
       " (u'thai', 0.0275),\n",
       " (u'vietnamese', 0.025000000000000001)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display classes with probabilities\n",
    "zip(knn.classes_, new_pred_prob_knn[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted probabilities will sum to 1 for each row\n",
    "new_pred_prob_knn[0, :].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Naive Bayes model using only text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "        vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=0.302332572632, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the best model found by RandomizedSearchCV\n",
    "rand.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X_new as the ingredient text\n",
    "X_new = new.ingredients_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944L, 20L)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities of class membership for the new data\n",
    "new_pred_prob_rand = rand.predict_proba(X_new)\n",
    "new_pred_prob_rand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.35624509e-04,   5.10677208e-01,   5.01039760e-05,\n",
       "         7.46758455e-05,   3.64528916e-03,   1.36909784e-03,\n",
       "         4.25463842e-04,   3.16817133e-04,   1.85847350e-01,\n",
       "         3.78331630e-03,   2.67495007e-04,   5.60369424e-04,\n",
       "         4.27190054e-06,   8.85175984e-04,   8.50499605e-06,\n",
       "         3.04368393e-02,   2.60701445e-01,   3.09630257e-04,\n",
       "         1.07646647e-06,   2.45297976e-07])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print predicted probabilities for the first row only\n",
    "new_pred_prob_rand[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling models 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01344281,  0.2690886 ,  0.00690005,  0.02191234,  0.01869764,\n",
       "        0.04068455,  0.00896273,  0.03765841,  0.10667368,  0.06939166,\n",
       "        0.00513375,  0.03778018,  0.00937714,  0.08294259,  0.00437925,\n",
       "        0.02146842,  0.20660072,  0.01265482,  0.01375054,  0.01250012])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean of the predicted probabilities for the first row\n",
    "(new_pred_prob_knn[0, :] + new_pred_prob_rand[0, :]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brazilian</th>\n",
       "      <th>british</th>\n",
       "      <th>cajun_creole</th>\n",
       "      <th>chinese</th>\n",
       "      <th>filipino</th>\n",
       "      <th>french</th>\n",
       "      <th>greek</th>\n",
       "      <th>indian</th>\n",
       "      <th>irish</th>\n",
       "      <th>italian</th>\n",
       "      <th>jamaican</th>\n",
       "      <th>japanese</th>\n",
       "      <th>korean</th>\n",
       "      <th>mexican</th>\n",
       "      <th>moroccan</th>\n",
       "      <th>russian</th>\n",
       "      <th>southern_us</th>\n",
       "      <th>spanish</th>\n",
       "      <th>thai</th>\n",
       "      <th>vietnamese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013443</td>\n",
       "      <td>0.269089</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.021912</td>\n",
       "      <td>0.018698</td>\n",
       "      <td>0.040685</td>\n",
       "      <td>0.008963</td>\n",
       "      <td>0.037658</td>\n",
       "      <td>0.106674</td>\n",
       "      <td>0.069392</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>0.037780</td>\n",
       "      <td>0.009377</td>\n",
       "      <td>0.082943</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>0.206601</td>\n",
       "      <td>0.012655</td>\n",
       "      <td>0.013751</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.011324</td>\n",
       "      <td>0.016875</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.018132</td>\n",
       "      <td>0.023884</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.046250</td>\n",
       "      <td>0.010629</td>\n",
       "      <td>0.070625</td>\n",
       "      <td>0.005626</td>\n",
       "      <td>0.027501</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.066875</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.547901</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.025625</td>\n",
       "      <td>0.013125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.009389</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.015010</td>\n",
       "      <td>0.041365</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.029376</td>\n",
       "      <td>0.013372</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.038752</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.080630</td>\n",
       "      <td>0.025887</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.079377</td>\n",
       "      <td>0.158440</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.012502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.533750</td>\n",
       "      <td>0.038750</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.023125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.075625</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.051875</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.029375</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.038125</td>\n",
       "      <td>0.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.020097</td>\n",
       "      <td>0.021250</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.017501</td>\n",
       "      <td>0.013750</td>\n",
       "      <td>0.012547</td>\n",
       "      <td>0.640841</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.083129</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.072838</td>\n",
       "      <td>0.018252</td>\n",
       "      <td>0.014375</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brazilian   british  cajun_creole   chinese  filipino    french     greek  \\\n",
       "0   0.013443  0.269089      0.006900  0.021912  0.018698  0.040685  0.008963   \n",
       "1   0.008752  0.011324      0.016875  0.045000  0.018132  0.023884  0.015625   \n",
       "2   0.013158  0.009389      0.006951  0.020000  0.015010  0.041365  0.010101   \n",
       "3   0.003125  0.004375      0.533750  0.038750  0.001875  0.023125  0.006250   \n",
       "4   0.001878  0.009856      0.020097  0.021250  0.003125  0.044922  0.017501   \n",
       "\n",
       "     indian     irish   italian  jamaican  japanese    korean   mexican  \\\n",
       "0  0.037658  0.106674  0.069392  0.005134  0.037780  0.009377  0.082943   \n",
       "1  0.046250  0.010629  0.070625  0.005626  0.027501  0.021875  0.066875   \n",
       "2  0.029376  0.013372  0.408696  0.005628  0.038752  0.007500  0.080630   \n",
       "3  0.075625  0.001250  0.051875  0.011875  0.008125  0.003125  0.107500   \n",
       "4  0.013750  0.012547  0.640841  0.003752  0.007500  0.003750  0.083129   \n",
       "\n",
       "   moroccan   russian  southern_us   spanish      thai  vietnamese  \n",
       "0  0.004379  0.021468     0.206601  0.012655  0.013751    0.012500  \n",
       "1  0.008125  0.008750     0.547901  0.007500  0.025625    0.013125  \n",
       "2  0.025887  0.008240     0.079377  0.158440  0.015625    0.012502  \n",
       "3  0.029375  0.001875     0.025000  0.007500  0.038125    0.027500  \n",
       "4  0.004376  0.003135     0.072838  0.018252  0.014375    0.003125  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean of the predicted probabilities for all rows\n",
    "new_pred_prob = pd.DataFrame((new_pred_prob_knn + new_pred_prob_rand) / 2, columns=knn.classes_)\n",
    "new_pred_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         british\n",
       "1     southern_us\n",
       "2         italian\n",
       "3    cajun_creole\n",
       "4         italian\n",
       "dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each row, find the column with the highest predicted probability\n",
    "new_pred_class = new_pred_prob.apply(np.argmax, axis=1)\n",
    "new_pred_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a submission file (score: 0.75241)\n",
    "pd.DataFrame({'id':new.id, 'cuisine':new_pred_class}).set_index('id').to_csv('sub4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** [VotingClassifier](http://scikit-learn.org/stable/modules/ensemble.html#votingclassifier) (new in 0.17) makes it easier to ensemble classifiers, though it is limited to the case in which all of the classifiers are fit to the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Locating groups of similar cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuisine\n",
       "brazilian       [u'ice cubes', u'club soda', u'white rum', u'l...\n",
       "british         [u'greek yogurt', u'lemon curd', u'confectione...\n",
       "cajun_creole    [u'herbs', u'lemon juice', u'fresh tomatoes', ...\n",
       "chinese         [u'low sodium soy sauce', u'fresh ginger', u'd...\n",
       "filipino        [u'eggs', u'pepper', u'salt', u'mayonaise', u'...\n",
       "french          [u'sugar', u'salt', u'fennel bulb', u'water', ...\n",
       "greek           [u'romaine lettuce', u'black olives', u'grape ...\n",
       "indian          [u'water', u'vegetable oil', u'wheat', u'salt'...\n",
       "irish           [u'cooking spray', u'salt', u'black pepper', u...\n",
       "italian         [u'sugar', u'pistachio nuts', u'white almond b...\n",
       "jamaican        [u'plain flour', u'sugar', u'butter', u'eggs',...\n",
       "japanese        [u'sirloin', u'mirin', u'yellow onion', u'low ...\n",
       "korean          [u'jasmine rice', u'garlic', u'scallions', u's...\n",
       "mexican         [u'olive oil', u'purple onion', u'fresh pineap...\n",
       "moroccan        [u'ground cloves', u'whole nutmegs', u'ground ...\n",
       "russian         [u'water', u'grits', u'mozzarella cheese', u's...\n",
       "southern_us     [u'plain flour', u'ground pepper', u'salt', u'...\n",
       "spanish         [u'olive oil', u'salt', u'medium shrimp', u'pe...\n",
       "thai            [u'sugar', u'hot chili', u'asian fish sauce', ...\n",
       "vietnamese      [u'soy sauce', u'vegetable oil', u'red bell pe...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each cuisine, combine all of the recipes into a single string\n",
    "cuisine_ingredients = train.groupby('cuisine').ingredients_str.sum()\n",
    "cuisine_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[u'ice cubes', u'club soda', u'white rum', u'lime', u'turbinado'][u'eggs', u'hearts of palm', u'cilantro', u'coconut cream', u'flax seed meal', u'kosher salt', u'jalapeno chilies', u'garlic', u'cream cheese, soften', u'coconut oil', u'lime juice', u'crushed red pepper flakes', u'ground coriander', u'pepper', u'chicken breasts', u'coconut flour', u'onions'][u'sweetened condensed milk', u'butter', u'cocoa powder'][u'lime', u'crushed ice', u'simple syrup', u'cachaca'][u'sugar', u'corn starch', u'eg\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the brazilian ingredients\n",
    "cuisine_ingredients['brazilian'][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41     [u'ice cubes', u'club soda', u'white rum', u'l...\n",
       "380    [u'eggs', u'hearts of palm', u'cilantro', u'co...\n",
       "423    [u'sweetened condensed milk', u'butter', u'coc...\n",
       "509    [u'lime', u'crushed ice', u'simple syrup', u'c...\n",
       "724    [u'sugar', u'corn starch', u'egg whites', u'bo...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that they match the brazilian recipes\n",
    "train.loc[train.cuisine=='brazilian', 'ingredients_str'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 3028)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a document-term matrix from cuisine_ingredients\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "cuisine_dtm = vect.fit_transform(cuisine_ingredients)\n",
    "cuisine_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How to calculate document similarity](http://stackoverflow.com/questions/12118720/python-tf-idf-cosine-to-find-document-similarity/12128777#12128777) (Stack Overflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate the cosine similarity between each cuisine and all other cuisines\n",
    "from sklearn import metrics\n",
    "cuisine_similarity = []\n",
    "for idx in range(cuisine_dtm.shape[0]):\n",
    "    similarity = metrics.pairwise.linear_kernel(cuisine_dtm[idx, :], cuisine_dtm).flatten()\n",
    "    cuisine_similarity.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cuisine</th>\n",
       "      <th>brazilian</th>\n",
       "      <th>british</th>\n",
       "      <th>cajun_creole</th>\n",
       "      <th>chinese</th>\n",
       "      <th>filipino</th>\n",
       "      <th>french</th>\n",
       "      <th>greek</th>\n",
       "      <th>indian</th>\n",
       "      <th>irish</th>\n",
       "      <th>italian</th>\n",
       "      <th>jamaican</th>\n",
       "      <th>japanese</th>\n",
       "      <th>korean</th>\n",
       "      <th>mexican</th>\n",
       "      <th>moroccan</th>\n",
       "      <th>russian</th>\n",
       "      <th>southern_us</th>\n",
       "      <th>spanish</th>\n",
       "      <th>thai</th>\n",
       "      <th>vietnamese</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuisine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brazilian</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660156</td>\n",
       "      <td>0.742322</td>\n",
       "      <td>0.580757</td>\n",
       "      <td>0.769215</td>\n",
       "      <td>0.755767</td>\n",
       "      <td>0.695686</td>\n",
       "      <td>0.687244</td>\n",
       "      <td>0.665677</td>\n",
       "      <td>0.740519</td>\n",
       "      <td>0.778320</td>\n",
       "      <td>0.555601</td>\n",
       "      <td>0.571439</td>\n",
       "      <td>0.743713</td>\n",
       "      <td>0.669002</td>\n",
       "      <td>0.705931</td>\n",
       "      <td>0.743146</td>\n",
       "      <td>0.807689</td>\n",
       "      <td>0.685539</td>\n",
       "      <td>0.653800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>british</th>\n",
       "      <td>0.660156</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.591167</td>\n",
       "      <td>0.467593</td>\n",
       "      <td>0.631277</td>\n",
       "      <td>0.859299</td>\n",
       "      <td>0.562693</td>\n",
       "      <td>0.560318</td>\n",
       "      <td>0.926662</td>\n",
       "      <td>0.632588</td>\n",
       "      <td>0.661978</td>\n",
       "      <td>0.508248</td>\n",
       "      <td>0.447121</td>\n",
       "      <td>0.560398</td>\n",
       "      <td>0.543230</td>\n",
       "      <td>0.909555</td>\n",
       "      <td>0.911177</td>\n",
       "      <td>0.603975</td>\n",
       "      <td>0.445473</td>\n",
       "      <td>0.478860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cajun_creole</th>\n",
       "      <td>0.742322</td>\n",
       "      <td>0.591167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.605581</td>\n",
       "      <td>0.746149</td>\n",
       "      <td>0.708263</td>\n",
       "      <td>0.688395</td>\n",
       "      <td>0.618938</td>\n",
       "      <td>0.635172</td>\n",
       "      <td>0.738158</td>\n",
       "      <td>0.780895</td>\n",
       "      <td>0.532397</td>\n",
       "      <td>0.578644</td>\n",
       "      <td>0.724866</td>\n",
       "      <td>0.649826</td>\n",
       "      <td>0.657667</td>\n",
       "      <td>0.747479</td>\n",
       "      <td>0.803631</td>\n",
       "      <td>0.590103</td>\n",
       "      <td>0.605223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>0.580757</td>\n",
       "      <td>0.467593</td>\n",
       "      <td>0.605581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839802</td>\n",
       "      <td>0.540009</td>\n",
       "      <td>0.496090</td>\n",
       "      <td>0.553515</td>\n",
       "      <td>0.460728</td>\n",
       "      <td>0.555503</td>\n",
       "      <td>0.635953</td>\n",
       "      <td>0.835586</td>\n",
       "      <td>0.866827</td>\n",
       "      <td>0.561824</td>\n",
       "      <td>0.505653</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.558511</td>\n",
       "      <td>0.603523</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.817003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filipino</th>\n",
       "      <td>0.769215</td>\n",
       "      <td>0.631277</td>\n",
       "      <td>0.746149</td>\n",
       "      <td>0.839802</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.682372</td>\n",
       "      <td>0.607433</td>\n",
       "      <td>0.655896</td>\n",
       "      <td>0.640979</td>\n",
       "      <td>0.670621</td>\n",
       "      <td>0.792723</td>\n",
       "      <td>0.748554</td>\n",
       "      <td>0.782623</td>\n",
       "      <td>0.678285</td>\n",
       "      <td>0.614970</td>\n",
       "      <td>0.696845</td>\n",
       "      <td>0.720363</td>\n",
       "      <td>0.727401</td>\n",
       "      <td>0.741510</td>\n",
       "      <td>0.806831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>french</th>\n",
       "      <td>0.755767</td>\n",
       "      <td>0.859299</td>\n",
       "      <td>0.708263</td>\n",
       "      <td>0.540009</td>\n",
       "      <td>0.682372</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759303</td>\n",
       "      <td>0.624355</td>\n",
       "      <td>0.836959</td>\n",
       "      <td>0.834680</td>\n",
       "      <td>0.722627</td>\n",
       "      <td>0.539835</td>\n",
       "      <td>0.501789</td>\n",
       "      <td>0.666329</td>\n",
       "      <td>0.684843</td>\n",
       "      <td>0.880922</td>\n",
       "      <td>0.861419</td>\n",
       "      <td>0.816989</td>\n",
       "      <td>0.547923</td>\n",
       "      <td>0.570485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greek</th>\n",
       "      <td>0.695686</td>\n",
       "      <td>0.562693</td>\n",
       "      <td>0.688395</td>\n",
       "      <td>0.496090</td>\n",
       "      <td>0.607433</td>\n",
       "      <td>0.759303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640285</td>\n",
       "      <td>0.583655</td>\n",
       "      <td>0.859268</td>\n",
       "      <td>0.681278</td>\n",
       "      <td>0.469471</td>\n",
       "      <td>0.479832</td>\n",
       "      <td>0.696638</td>\n",
       "      <td>0.769405</td>\n",
       "      <td>0.649402</td>\n",
       "      <td>0.641235</td>\n",
       "      <td>0.837435</td>\n",
       "      <td>0.519005</td>\n",
       "      <td>0.538680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indian</th>\n",
       "      <td>0.687244</td>\n",
       "      <td>0.560318</td>\n",
       "      <td>0.618938</td>\n",
       "      <td>0.553515</td>\n",
       "      <td>0.655896</td>\n",
       "      <td>0.624355</td>\n",
       "      <td>0.640285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577297</td>\n",
       "      <td>0.616204</td>\n",
       "      <td>0.734893</td>\n",
       "      <td>0.567991</td>\n",
       "      <td>0.538822</td>\n",
       "      <td>0.708576</td>\n",
       "      <td>0.795278</td>\n",
       "      <td>0.607321</td>\n",
       "      <td>0.617247</td>\n",
       "      <td>0.678842</td>\n",
       "      <td>0.627444</td>\n",
       "      <td>0.605132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irish</th>\n",
       "      <td>0.665677</td>\n",
       "      <td>0.926662</td>\n",
       "      <td>0.635172</td>\n",
       "      <td>0.460728</td>\n",
       "      <td>0.640979</td>\n",
       "      <td>0.836959</td>\n",
       "      <td>0.583655</td>\n",
       "      <td>0.577297</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649873</td>\n",
       "      <td>0.680880</td>\n",
       "      <td>0.494742</td>\n",
       "      <td>0.458775</td>\n",
       "      <td>0.591703</td>\n",
       "      <td>0.563278</td>\n",
       "      <td>0.892391</td>\n",
       "      <td>0.902821</td>\n",
       "      <td>0.630912</td>\n",
       "      <td>0.449910</td>\n",
       "      <td>0.481697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>italian</th>\n",
       "      <td>0.740519</td>\n",
       "      <td>0.632588</td>\n",
       "      <td>0.738158</td>\n",
       "      <td>0.555503</td>\n",
       "      <td>0.670621</td>\n",
       "      <td>0.834680</td>\n",
       "      <td>0.859268</td>\n",
       "      <td>0.616204</td>\n",
       "      <td>0.649873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695762</td>\n",
       "      <td>0.510283</td>\n",
       "      <td>0.522563</td>\n",
       "      <td>0.733954</td>\n",
       "      <td>0.709824</td>\n",
       "      <td>0.697503</td>\n",
       "      <td>0.718946</td>\n",
       "      <td>0.858160</td>\n",
       "      <td>0.555086</td>\n",
       "      <td>0.571094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jamaican</th>\n",
       "      <td>0.778320</td>\n",
       "      <td>0.661978</td>\n",
       "      <td>0.780895</td>\n",
       "      <td>0.635953</td>\n",
       "      <td>0.792723</td>\n",
       "      <td>0.722627</td>\n",
       "      <td>0.681278</td>\n",
       "      <td>0.734893</td>\n",
       "      <td>0.680880</td>\n",
       "      <td>0.695762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.584688</td>\n",
       "      <td>0.609204</td>\n",
       "      <td>0.731839</td>\n",
       "      <td>0.757450</td>\n",
       "      <td>0.684341</td>\n",
       "      <td>0.752855</td>\n",
       "      <td>0.751666</td>\n",
       "      <td>0.650899</td>\n",
       "      <td>0.664173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japanese</th>\n",
       "      <td>0.555601</td>\n",
       "      <td>0.508248</td>\n",
       "      <td>0.532397</td>\n",
       "      <td>0.835586</td>\n",
       "      <td>0.748554</td>\n",
       "      <td>0.539835</td>\n",
       "      <td>0.469471</td>\n",
       "      <td>0.567991</td>\n",
       "      <td>0.494742</td>\n",
       "      <td>0.510283</td>\n",
       "      <td>0.584688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.819824</td>\n",
       "      <td>0.506529</td>\n",
       "      <td>0.477408</td>\n",
       "      <td>0.557163</td>\n",
       "      <td>0.554021</td>\n",
       "      <td>0.547334</td>\n",
       "      <td>0.682605</td>\n",
       "      <td>0.738409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean</th>\n",
       "      <td>0.571439</td>\n",
       "      <td>0.447121</td>\n",
       "      <td>0.578644</td>\n",
       "      <td>0.866827</td>\n",
       "      <td>0.782623</td>\n",
       "      <td>0.501789</td>\n",
       "      <td>0.479832</td>\n",
       "      <td>0.538822</td>\n",
       "      <td>0.458775</td>\n",
       "      <td>0.522563</td>\n",
       "      <td>0.609204</td>\n",
       "      <td>0.819824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.516448</td>\n",
       "      <td>0.477953</td>\n",
       "      <td>0.517565</td>\n",
       "      <td>0.516808</td>\n",
       "      <td>0.582963</td>\n",
       "      <td>0.671053</td>\n",
       "      <td>0.747117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mexican</th>\n",
       "      <td>0.743713</td>\n",
       "      <td>0.560398</td>\n",
       "      <td>0.724866</td>\n",
       "      <td>0.561824</td>\n",
       "      <td>0.678285</td>\n",
       "      <td>0.666329</td>\n",
       "      <td>0.696638</td>\n",
       "      <td>0.708576</td>\n",
       "      <td>0.591703</td>\n",
       "      <td>0.733954</td>\n",
       "      <td>0.731839</td>\n",
       "      <td>0.506529</td>\n",
       "      <td>0.516448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.697416</td>\n",
       "      <td>0.630440</td>\n",
       "      <td>0.691391</td>\n",
       "      <td>0.739852</td>\n",
       "      <td>0.617611</td>\n",
       "      <td>0.623522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moroccan</th>\n",
       "      <td>0.669002</td>\n",
       "      <td>0.543230</td>\n",
       "      <td>0.649826</td>\n",
       "      <td>0.505653</td>\n",
       "      <td>0.614970</td>\n",
       "      <td>0.684843</td>\n",
       "      <td>0.769405</td>\n",
       "      <td>0.795278</td>\n",
       "      <td>0.563278</td>\n",
       "      <td>0.709824</td>\n",
       "      <td>0.757450</td>\n",
       "      <td>0.477408</td>\n",
       "      <td>0.477953</td>\n",
       "      <td>0.697416</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608238</td>\n",
       "      <td>0.605945</td>\n",
       "      <td>0.784603</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>0.553366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>russian</th>\n",
       "      <td>0.705931</td>\n",
       "      <td>0.909555</td>\n",
       "      <td>0.657667</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.696845</td>\n",
       "      <td>0.880922</td>\n",
       "      <td>0.649402</td>\n",
       "      <td>0.607321</td>\n",
       "      <td>0.892391</td>\n",
       "      <td>0.697503</td>\n",
       "      <td>0.684341</td>\n",
       "      <td>0.557163</td>\n",
       "      <td>0.517565</td>\n",
       "      <td>0.630440</td>\n",
       "      <td>0.608238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877742</td>\n",
       "      <td>0.702654</td>\n",
       "      <td>0.494228</td>\n",
       "      <td>0.539003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>southern_us</th>\n",
       "      <td>0.743146</td>\n",
       "      <td>0.911177</td>\n",
       "      <td>0.747479</td>\n",
       "      <td>0.558511</td>\n",
       "      <td>0.720363</td>\n",
       "      <td>0.861419</td>\n",
       "      <td>0.641235</td>\n",
       "      <td>0.617247</td>\n",
       "      <td>0.902821</td>\n",
       "      <td>0.718946</td>\n",
       "      <td>0.752855</td>\n",
       "      <td>0.554021</td>\n",
       "      <td>0.516808</td>\n",
       "      <td>0.691391</td>\n",
       "      <td>0.605945</td>\n",
       "      <td>0.877742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707764</td>\n",
       "      <td>0.536960</td>\n",
       "      <td>0.562356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spanish</th>\n",
       "      <td>0.807689</td>\n",
       "      <td>0.603975</td>\n",
       "      <td>0.803631</td>\n",
       "      <td>0.603523</td>\n",
       "      <td>0.727401</td>\n",
       "      <td>0.816989</td>\n",
       "      <td>0.837435</td>\n",
       "      <td>0.678842</td>\n",
       "      <td>0.630912</td>\n",
       "      <td>0.858160</td>\n",
       "      <td>0.751666</td>\n",
       "      <td>0.547334</td>\n",
       "      <td>0.582963</td>\n",
       "      <td>0.739852</td>\n",
       "      <td>0.784603</td>\n",
       "      <td>0.702654</td>\n",
       "      <td>0.707764</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606197</td>\n",
       "      <td>0.614199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thai</th>\n",
       "      <td>0.685539</td>\n",
       "      <td>0.445473</td>\n",
       "      <td>0.590103</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.741510</td>\n",
       "      <td>0.547923</td>\n",
       "      <td>0.519005</td>\n",
       "      <td>0.627444</td>\n",
       "      <td>0.449910</td>\n",
       "      <td>0.555086</td>\n",
       "      <td>0.650899</td>\n",
       "      <td>0.682605</td>\n",
       "      <td>0.671053</td>\n",
       "      <td>0.617611</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>0.494228</td>\n",
       "      <td>0.536960</td>\n",
       "      <td>0.606197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vietnamese</th>\n",
       "      <td>0.653800</td>\n",
       "      <td>0.478860</td>\n",
       "      <td>0.605223</td>\n",
       "      <td>0.817003</td>\n",
       "      <td>0.806831</td>\n",
       "      <td>0.570485</td>\n",
       "      <td>0.538680</td>\n",
       "      <td>0.605132</td>\n",
       "      <td>0.481697</td>\n",
       "      <td>0.571094</td>\n",
       "      <td>0.664173</td>\n",
       "      <td>0.738409</td>\n",
       "      <td>0.747117</td>\n",
       "      <td>0.623522</td>\n",
       "      <td>0.553366</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.562356</td>\n",
       "      <td>0.614199</td>\n",
       "      <td>0.914983</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cuisine       brazilian   british  cajun_creole   chinese  filipino    french  \\\n",
       "cuisine                                                                         \n",
       "brazilian      1.000000  0.660156      0.742322  0.580757  0.769215  0.755767   \n",
       "british        0.660156  1.000000      0.591167  0.467593  0.631277  0.859299   \n",
       "cajun_creole   0.742322  0.591167      1.000000  0.605581  0.746149  0.708263   \n",
       "chinese        0.580757  0.467593      0.605581  1.000000  0.839802  0.540009   \n",
       "filipino       0.769215  0.631277      0.746149  0.839802  1.000000  0.682372   \n",
       "french         0.755767  0.859299      0.708263  0.540009  0.682372  1.000000   \n",
       "greek          0.695686  0.562693      0.688395  0.496090  0.607433  0.759303   \n",
       "indian         0.687244  0.560318      0.618938  0.553515  0.655896  0.624355   \n",
       "irish          0.665677  0.926662      0.635172  0.460728  0.640979  0.836959   \n",
       "italian        0.740519  0.632588      0.738158  0.555503  0.670621  0.834680   \n",
       "jamaican       0.778320  0.661978      0.780895  0.635953  0.792723  0.722627   \n",
       "japanese       0.555601  0.508248      0.532397  0.835586  0.748554  0.539835   \n",
       "korean         0.571439  0.447121      0.578644  0.866827  0.782623  0.501789   \n",
       "mexican        0.743713  0.560398      0.724866  0.561824  0.678285  0.666329   \n",
       "moroccan       0.669002  0.543230      0.649826  0.505653  0.614970  0.684843   \n",
       "russian        0.705931  0.909555      0.657667  0.521739  0.696845  0.880922   \n",
       "southern_us    0.743146  0.911177      0.747479  0.558511  0.720363  0.861419   \n",
       "spanish        0.807689  0.603975      0.803631  0.603523  0.727401  0.816989   \n",
       "thai           0.685539  0.445473      0.590103  0.755814  0.741510  0.547923   \n",
       "vietnamese     0.653800  0.478860      0.605223  0.817003  0.806831  0.570485   \n",
       "\n",
       "cuisine          greek    indian     irish   italian  jamaican  japanese  \\\n",
       "cuisine                                                                    \n",
       "brazilian     0.695686  0.687244  0.665677  0.740519  0.778320  0.555601   \n",
       "british       0.562693  0.560318  0.926662  0.632588  0.661978  0.508248   \n",
       "cajun_creole  0.688395  0.618938  0.635172  0.738158  0.780895  0.532397   \n",
       "chinese       0.496090  0.553515  0.460728  0.555503  0.635953  0.835586   \n",
       "filipino      0.607433  0.655896  0.640979  0.670621  0.792723  0.748554   \n",
       "french        0.759303  0.624355  0.836959  0.834680  0.722627  0.539835   \n",
       "greek         1.000000  0.640285  0.583655  0.859268  0.681278  0.469471   \n",
       "indian        0.640285  1.000000  0.577297  0.616204  0.734893  0.567991   \n",
       "irish         0.583655  0.577297  1.000000  0.649873  0.680880  0.494742   \n",
       "italian       0.859268  0.616204  0.649873  1.000000  0.695762  0.510283   \n",
       "jamaican      0.681278  0.734893  0.680880  0.695762  1.000000  0.584688   \n",
       "japanese      0.469471  0.567991  0.494742  0.510283  0.584688  1.000000   \n",
       "korean        0.479832  0.538822  0.458775  0.522563  0.609204  0.819824   \n",
       "mexican       0.696638  0.708576  0.591703  0.733954  0.731839  0.506529   \n",
       "moroccan      0.769405  0.795278  0.563278  0.709824  0.757450  0.477408   \n",
       "russian       0.649402  0.607321  0.892391  0.697503  0.684341  0.557163   \n",
       "southern_us   0.641235  0.617247  0.902821  0.718946  0.752855  0.554021   \n",
       "spanish       0.837435  0.678842  0.630912  0.858160  0.751666  0.547334   \n",
       "thai          0.519005  0.627444  0.449910  0.555086  0.650899  0.682605   \n",
       "vietnamese    0.538680  0.605132  0.481697  0.571094  0.664173  0.738409   \n",
       "\n",
       "cuisine         korean   mexican  moroccan   russian  southern_us   spanish  \\\n",
       "cuisine                                                                       \n",
       "brazilian     0.571439  0.743713  0.669002  0.705931     0.743146  0.807689   \n",
       "british       0.447121  0.560398  0.543230  0.909555     0.911177  0.603975   \n",
       "cajun_creole  0.578644  0.724866  0.649826  0.657667     0.747479  0.803631   \n",
       "chinese       0.866827  0.561824  0.505653  0.521739     0.558511  0.603523   \n",
       "filipino      0.782623  0.678285  0.614970  0.696845     0.720363  0.727401   \n",
       "french        0.501789  0.666329  0.684843  0.880922     0.861419  0.816989   \n",
       "greek         0.479832  0.696638  0.769405  0.649402     0.641235  0.837435   \n",
       "indian        0.538822  0.708576  0.795278  0.607321     0.617247  0.678842   \n",
       "irish         0.458775  0.591703  0.563278  0.892391     0.902821  0.630912   \n",
       "italian       0.522563  0.733954  0.709824  0.697503     0.718946  0.858160   \n",
       "jamaican      0.609204  0.731839  0.757450  0.684341     0.752855  0.751666   \n",
       "japanese      0.819824  0.506529  0.477408  0.557163     0.554021  0.547334   \n",
       "korean        1.000000  0.516448  0.477953  0.517565     0.516808  0.582963   \n",
       "mexican       0.516448  1.000000  0.697416  0.630440     0.691391  0.739852   \n",
       "moroccan      0.477953  0.697416  1.000000  0.608238     0.605945  0.784603   \n",
       "russian       0.517565  0.630440  0.608238  1.000000     0.877742  0.702654   \n",
       "southern_us   0.516808  0.691391  0.605945  0.877742     1.000000  0.707764   \n",
       "spanish       0.582963  0.739852  0.784603  0.702654     0.707764  1.000000   \n",
       "thai          0.671053  0.617611  0.533128  0.494228     0.536960  0.606197   \n",
       "vietnamese    0.747117  0.623522  0.553366  0.539003     0.562356  0.614199   \n",
       "\n",
       "cuisine           thai  vietnamese  \n",
       "cuisine                             \n",
       "brazilian     0.685539    0.653800  \n",
       "british       0.445473    0.478860  \n",
       "cajun_creole  0.590103    0.605223  \n",
       "chinese       0.755814    0.817003  \n",
       "filipino      0.741510    0.806831  \n",
       "french        0.547923    0.570485  \n",
       "greek         0.519005    0.538680  \n",
       "indian        0.627444    0.605132  \n",
       "irish         0.449910    0.481697  \n",
       "italian       0.555086    0.571094  \n",
       "jamaican      0.650899    0.664173  \n",
       "japanese      0.682605    0.738409  \n",
       "korean        0.671053    0.747117  \n",
       "mexican       0.617611    0.623522  \n",
       "moroccan      0.533128    0.553366  \n",
       "russian       0.494228    0.539003  \n",
       "southern_us   0.536960    0.562356  \n",
       "spanish       0.606197    0.614199  \n",
       "thai          1.000000    0.914983  \n",
       "vietnamese    0.914983    1.000000  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the results to a DataFrame\n",
    "cuisine_list = cuisine_ingredients.index\n",
    "cuisine_similarity = pd.DataFrame(cuisine_similarity, index=cuisine_list, columns=cuisine_list)\n",
    "cuisine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kevin\\Anaconda\\lib\\site-packages\\matplotlib\\__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xee65048>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAGUCAYAAAA/N/saAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAGuoRtsVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xee47940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the similarities as a heatmap\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.heatmap(cuisine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hand-selected cuisine groups\n",
    "group_1 = ['chinese', 'filipino', 'japanese', 'korean', 'thai', 'vietnamese']\n",
    "group_2 = ['british', 'french', 'irish', 'russian', 'southern_us']\n",
    "group_3 = ['greek', 'italian', 'moroccan', 'spanish']\n",
    "group_4 = ['brazilian', 'cajun_creole', 'indian', 'jamaican', 'mexican']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Model stacking\n",
    "\n",
    "- The term \"model stacking\" is used any time there are **multiple \"levels\" of models**, in which the outputs from one level are used as inputs to another level.\n",
    "- In this case, we will create one model that predicts the **cuisine group** for a recipe. Within each of the four groups, we will create another model that predicts the actual **cuisine**.\n",
    "- Our theory is that each of these five models may need to be **tuned differently** for maximum accuracy, but will ultimately result in a process that is more accurate than a single-level model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brazilian': 4,\n",
       " 'british': 2,\n",
       " 'cajun_creole': 4,\n",
       " 'chinese': 1,\n",
       " 'filipino': 1,\n",
       " 'french': 2,\n",
       " 'greek': 3,\n",
       " 'indian': 4,\n",
       " 'irish': 2,\n",
       " 'italian': 3,\n",
       " 'jamaican': 4,\n",
       " 'japanese': 1,\n",
       " 'korean': 1,\n",
       " 'mexican': 4,\n",
       " 'moroccan': 3,\n",
       " 'russian': 2,\n",
       " 'southern_us': 2,\n",
       " 'spanish': 3,\n",
       " 'thai': 1,\n",
       " 'vietnamese': 1}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary that maps each cuisine to its group number\n",
    "cuisines = group_1 + group_2 + group_3 + group_4\n",
    "group_numbers = [1]*len(group_1) + [2]*len(group_2) + [3]*len(group_3) + [4]*len(group_4)\n",
    "cuisine_to_group = dict(zip(cuisines, group_numbers))\n",
    "cuisine_to_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>[u'romaine lettuce', u'black olives', u'grape ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "      <td>[u'plain flour', u'ground pepper', u'salt', u'...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>[u'eggs', u'pepper', u'salt', u'mayonaise', u'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>[u'water', u'vegetable oil', u'wheat', u'salt']</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>[u'black pepper', u'shallots', u'cornflour', u...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients  \\\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]   \n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "   num_ingredients  ingredient_length  \\\n",
       "0                9          12.000000   \n",
       "1               11          10.090909   \n",
       "2               12          10.333333   \n",
       "3                4           6.750000   \n",
       "4               20          10.100000   \n",
       "\n",
       "                                     ingredients_str  group  \n",
       "0  [u'romaine lettuce', u'black olives', u'grape ...      3  \n",
       "1  [u'plain flour', u'ground pepper', u'salt', u'...      2  \n",
       "2  [u'eggs', u'pepper', u'salt', u'mayonaise', u'...      1  \n",
       "3    [u'water', u'vegetable oil', u'wheat', u'salt']      4  \n",
       "4  [u'black pepper', u'shallots', u'cornflour', u...      4  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map the cuisines to their group numbers\n",
    "train['group'] = train.cuisine.map(cuisine_to_group)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that all recipes were assigned a cuisine group\n",
    "train.group.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82765137960555035"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the cross-validated accuracy of using text to predict cuisine group\n",
    "X = train.ingredients_str\n",
    "y = train.group\n",
    "pipe_main = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "cross_val_score(pipe_main, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define an X and y for each cuisine group\n",
    "X1 = train.loc[train.group==1, 'ingredients_str']\n",
    "y1 = train.loc[train.group==1, 'cuisine']\n",
    "X2 = train.loc[train.group==2, 'ingredients_str']\n",
    "y2 = train.loc[train.group==2, 'cuisine']\n",
    "X3 = train.loc[train.group==3, 'ingredients_str']\n",
    "y3 = train.loc[train.group==3, 'cuisine']\n",
    "X4 = train.loc[train.group==4, 'ingredients_str']\n",
    "y4 = train.loc[train.group==4, 'cuisine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a pipeline for each cuisine group\n",
    "pipe_1 = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "pipe_2 = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "pipe_3 = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "pipe_4 = make_pipeline(CountVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.769054289191\n",
      "0.757672844551\n",
      "0.869907044834\n",
      "0.904089986908\n"
     ]
    }
   ],
   "source": [
    "# within each cuisine group, calculate the cross-validated accuracy of using text to predict cuisine\n",
    "print(cross_val_score(pipe_1, X1, y1, cv=5, scoring='accuracy').mean())\n",
    "print(cross_val_score(pipe_2, X2, y2, cv=5, scoring='accuracy').mean())\n",
    "print(cross_val_score(pipe_3, X3, y3, cv=5, scoring='accuracy').mean())\n",
    "print(cross_val_score(pipe_4, X4, y4, cv=5, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Ideally, each of the five pipelines should be **individually tuned** from start to finish, including feature engineering, model selection, and parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions for the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit each pipeline with the relevant X and y\n",
    "pipe_main.fit(X, y)\n",
    "pipe_1.fit(X1, y1)\n",
    "pipe_2.fit(X2, y2)\n",
    "pipe_3.fit(X3, y3)\n",
    "pipe_4.fit(X4, y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 3, ..., 3, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the new data, first make cuisine group predictions\n",
    "X_new = new.ingredients_str\n",
    "new_pred_group = pipe_main.predict(X_new)\n",
    "new_pred_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'chinese' u'japanese' u'vietnamese' ..., u'chinese' u'chinese'\n",
      " u'vietnamese']\n",
      "[u'british' u'southern_us' u'southern_us' ..., u'southern_us' u'french'\n",
      " u'french']\n",
      "[u'spanish' u'italian' u'spanish' ..., u'italian' u'italian' u'italian']\n",
      "[u'cajun_creole' u'mexican' u'indian' ..., u'mexican' u'cajun_creole'\n",
      " u'mexican']\n"
     ]
    }
   ],
   "source": [
    "# then within each predicted cuisine group, make cuisine predictions\n",
    "new_pred_class_1 = pipe_1.predict(X_new[new_pred_group==1])\n",
    "new_pred_class_2 = pipe_2.predict(X_new[new_pred_group==2])\n",
    "new_pred_class_3 = pipe_3.predict(X_new[new_pred_group==3])\n",
    "new_pred_class_4 = pipe_4.predict(X_new[new_pred_group==4])\n",
    "print(new_pred_class_1)\n",
    "print(new_pred_class_2)\n",
    "print(new_pred_class_3)\n",
    "print(new_pred_class_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add the cuisine predictions to the DataFrame of new data\n",
    "new.loc[new_pred_group==1, 'pred_class'] = new_pred_class_1\n",
    "new.loc[new_pred_group==2, 'pred_class'] = new_pred_class_2\n",
    "new.loc[new_pred_group==3, 'pred_class'] = new_pred_class_3\n",
    "new.loc[new_pred_group==4, 'pred_class'] = new_pred_class_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "      <th>pred_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>[baking powder, eggs, all-purpose flour, raisi...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>[u'baking powder', u'eggs', u'all-purpose flou...</td>\n",
       "      <td>british</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>[sugar, egg yolks, corn starch, cream of tarta...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.272727</td>\n",
       "      <td>[u'sugar', u'egg yolks', u'corn starch', u'cre...</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>[sausage links, fennel bulb, fronds, olive oil...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>[u'sausage links', u'fennel bulb', u'fronds', ...</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>[meat cuts, file powder, smoked sausage, okra,...</td>\n",
       "      <td>21</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>[u'meat cuts', u'file powder', u'smoked sausag...</td>\n",
       "      <td>cajun_creole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>[ground black pepper, salt, sausage casings, l...</td>\n",
       "      <td>8</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>[u'ground black pepper', u'salt', u'sausage ca...</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        ingredients  num_ingredients  \\\n",
       "0  18009  [baking powder, eggs, all-purpose flour, raisi...                6   \n",
       "1  28583  [sugar, egg yolks, corn starch, cream of tarta...               11   \n",
       "2  41580  [sausage links, fennel bulb, fronds, olive oil...                6   \n",
       "3  29752  [meat cuts, file powder, smoked sausage, okra,...               21   \n",
       "4  35687  [ground black pepper, salt, sausage casings, l...                8   \n",
       "\n",
       "   ingredient_length                                    ingredients_str  \\\n",
       "0           9.333333  [u'baking powder', u'eggs', u'all-purpose flou...   \n",
       "1          10.272727  [u'sugar', u'egg yolks', u'corn starch', u'cre...   \n",
       "2           9.666667  [u'sausage links', u'fennel bulb', u'fronds', ...   \n",
       "3          12.000000  [u'meat cuts', u'file powder', u'smoked sausag...   \n",
       "4          13.000000  [u'ground black pepper', u'salt', u'sausage ca...   \n",
       "\n",
       "     pred_class  \n",
       "0       british  \n",
       "1   southern_us  \n",
       "2       spanish  \n",
       "3  cajun_creole  \n",
       "4       italian  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a submission file (score: 0.70475)\n",
    "pd.DataFrame({'id':new.id, 'cuisine':new.pred_class}).set_index('id').to_csv('sub5.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
